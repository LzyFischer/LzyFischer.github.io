<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Primary Meta Tags -->
    <title>Portfolio Template - Open source</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <meta name="title" content="Portfolio - Zhenyu Lei" />
    <meta
      name="description"
      content="Portfolio - Zhenyu Lei."
    />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta
      property="og:url"
      content="https://lzyfischer.github.io/"
    />
    <meta property="og:title" content="Portfolio - Zhenyu Lei" />
    <meta
      property="og:description"
      content="Portfolio - Zhenyu Leit"
    />
    <meta
      property="og:image"
      content="https://lzyfischer.github.io/assets/profile-image.jpeg"
    />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta
      property="twitter:url"
      content="https://lzyfischer.github.io/"
    />
    <meta property="twitter:title" content="Portfolio Zhenyu" />
    <meta
      property="twitter:description"
      content="Portfolio - Zhenyu Lei"
    />
    <meta
      property="twitter:image"
      content="https://lzyfischer.github.io/assets/profile-image.jpeg"
    />

    <!-- Link -->
    <link
      rel="apple-touch-icon"
      sizes="180x180"
      href="assets/favicon/apple-touch-icon.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="/assets/favicon/favicon-16x16.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="assets/favicon/favicon-32x32.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="192x192"
      href="assets/favicon/android-chrome-192x192.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="512x512"
      href="assets/favicon/android-chrome-512x512.png"
    />
    <link rel="icon" type="image/x-icon" href="assets/favicon/favicon.ico" />
    <link rel="manifest" href="assets/favicon/site.webmanifest" />
    <link
      rel="stylesheet"
      href="https://use.fontawesome.com/releases/v5.15.4/css/all.css"
      integrity="sha384-DyZ88mC6Up2uqS4h/KRgHuoeGwBcD4Ng9SiP4dIRy0EXTlnuz47vAwmeGwVChigm"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="css/style.css" />
    <link rel="stylesheet" href="css/utilities.css" />
  </head>

  <body>
    <header id="hero">
      <!-- Navbar -->
      <nav class="navbar">
        <div class="container">
          <!-- Logo -->
          <!-- <h1 id="logo">
            <a href="https://github.com/CommunityPro/portfolio-html"
              ><img src="./assets/logo.png" alt="Your Logo"
            /></a>
          </h1> -->
          <!-- Navbar links -->
          <ul class="nav-menu">
            <li><a class="nav-link" href="#education">EDUCATION</a></li>
            <li><a class="nav-link" href="#experience">EXPERIENCE</a></li>
            <li><a class="nav-link" href="#pub">PUBLICATIONS</a></li>
            <li><a class="nav-link" href="#service">SERVICE</a></li>
            <li><a class="nav-link" href="#misc">MISC</a></li>
            <!-- <li>
              <a
                class="nav-link btn btn-primary"
                href="https://github.com/CommunityPro/portfolio-html"
                >RESUME <i class="fas fa-arrow-right"></i
              ></a>
            </li> -->

            <!-- Toggle switch -->
            <div class="theme-switch">
              <input type="checkbox" id="switch" />
              <label class="toggle-icons" for="switch">
                <img class="moon" src="assets/moon.svg" />
                <img class="sun" src="assets/sun.svg" />
              </label>
            </div>
            <!-- Hamburger menu -->
          </ul>
          <div class="hamburger">
            <span class="bar"></span>
            <span class="bar"></span>
            <span class="bar"></span>
          </div>
        </div>
      </nav>

      

      <section class="header-container">
        <img class="profile-image" src="assets/profile-image.jpeg" alt="Profile Image" />
      
        <h1>Hi I'm Zhenyu (Fischer) Lei</h1>
      
        <div class="bio-text">
          I'm a PhD student at the University of Virginia. My ultimate goal is to <strong>make AI systems more accessible</strong> . My current interests lie in:        
          <ul class="bio-list">
            <li><strong>Efficiency</strong>: Especially how to distill the whole ability of larger black-box (or white-box) models into smaller ones. </li>
            <li><strong>Reliability</strong>: How to make accessible models more reliable.</li>
          </ul>
          My current side projects include:
          <ul class="bio-list">
            <li><strong>AI for Urban+Environment</strong>: How does AI helps in air quality and disaster mangement.</li>
            <li><strong>AI for Neuroscience</strong>: How to use AI to understand the brain.</li>
          </ul>

          I also have experience in solving real-world challenges with LLMs (ACL23, ACL25), graph models (ACL24, AAAI25), spatial-temporal models (AAAI25), AI for neuroscience (AAAI25), AI for biochemistry (Arxiv), and fairness algorithms (WWW24). If you are interested in my research, please feel free to reach out!
        </div>

        <div class="social-links">
          Email: 
          <span class="email-box">vjd5zr [at] virginia [dot] edu</span> / 
          <span class="email-box">vjd5zr [at] outlook [dot] com</span>
        </div>
      
        <div class="social-links">
          <a href="https://github.com/LzyFischer/LzyFischer.github.io/blob/main/assets/CV_lzy.pdf">CV</a> / <a href="https://scholar.google.com/citations?user=y4uMsEIAAAAJ&hl=en">Google Scholar</a> / <a href="https://x.com/FicsherLzy">Twitter</a>
        </div>
      </section>
        


        <!-- <div class="content-text">
          <h2>Building digital</h2>
          <h2>products, brands, and experience.</h2>

          <p>
            A Frontend Developer and Visual Designer with experience in web
            design, brand identity and product design.
          </p>
        </div> -->
        <!-- <a
          href="https://github.com/CommunityPro/portfolio-html"
          class="btn btn-secondary"
          target="_blank"
          >Connect With Me</a
        > -->
      </section>
    </header>

    

    <section class="news-section container">
      <h2>üî•What's New</h2>
      <div class="scroll-box">
        <ul class="news-list">
          <li>[2025.10] 1 papers get accepted to WSDM 2026! See you in Idaho! (Maybe)</li>
          <li>[2025.08] 2 papers get accepted to EMNLP! See you in Suzhou! (Maybe)</li>
          <li>[2025.01] <a href="#">Harnessing Large Language Models for Disaster Management: A Survey</a> is accepted to ACL Findings!</li>
          <li>[2024.11] 2 papers were accepted to AAAI 2025 Main (Oral)!üëè <a href="#">ST-FiT</a>, <a href="#">BrainMAP</a>. See you in Philadephia!</li>
        </ul>
      </div>
    </section>
    
    <section class="pub-section container" id="pub">
      <h2>
        üìñ Selected Publications 
        <span class="pub-note">(* indicates equal contribution)</span>
      </h2>

      <h3>2026</h3>
      <div class="pub-entry">
        <img src="assets/overview/moledit.png" alt="stfit diagram" />
        <div class="pub-details">
          <a class="pub-title" href="#">MolEdit: Knowledge Editing for Multimodal Molecule Language Models</a><br />
          <strong>Zhenyu Lei</strong>, Patrick Soga, Yaochen Zhu, Yinhan He, Yushun Dong, Jundong Li<br />
          <span class="preprint">WSDM 2026 (Oral)</span>
          <p>
            MolEdit is a framework for precisely editing facts inside multimodal molecule language models so they can fix outdated or wrong chemistry/biomed knowledge without retraining. It uses a Multi-Expert Knowledge Adapter (MEKA) to edit specific facets (e.g., functional groups, properties) and an Expertise-Aware Editing Switcher (EAES) to trigger edits only on closely matching inputs, plus MEBench to evaluate reliability, locality, and generality‚Äîshowing sizable gains over prior editors. 
          </p>
        </div>
      </div>

      <h3>2025</h3>
      <div class="pub-entry">
        <img src="assets/overview/qrdistill.png" alt="stfit diagram" />
        <div class="pub-details">
          <a class="pub-title" href="#">Learning from Diverse Reasoning Paths with Routing and Collaboration</a><br />
          <strong>Zhenyu Lei</strong>, Zhen Tan, Song Wang, Yaochen Zhu, Zihan Chen, Yushun Dong, Jundong Li<br />
          <span class="preprint">EMNLP 2025</span>
          <p>
            This work proposes <em>QR-Distill</em>, a distillation framework that (i) filters for correct, LLM-judged high-quality chains-of-thought, (ii) <em>conditionally routes</em> the remaining paths to students based on their current state, and (iii) enables <em>mutual student collaboration</em> via feature-level peer teaching. Across multiple reasoning datasets, it outperforms single- and multi-path baselines.
          </p>
        </div>
      </div>


      <div class="pub-entry">
        <img src="assets/overview/harnessing.jpeg" alt="stfit diagram" />
        <div class="pub-details">
          <a class="pub-title" href="#">Harnessing Large Language Models for Disaster Management: A Survey</a><br />
          <strong>Zhenyu Lei</strong>, Yushun Dong, Weiyu Li, Rong Ding, Qi R. Wang, Jundong Li<br />
          <span class="preprint">ACL 2025 Findings</span>
          <p>
            This survey systematically maps how LLMs support disaster management across mitigation, preparedness, response, and recovery. It introduces a unified taxonomy linking scenarios and tasks (classification, estimation, extraction, generation) to different model families, consolidates public datasets, and highlights open challenges‚Äîdataset construction, efficient deployment, robust generation, and unified evaluation‚Äîto guide future research and practice.  
          </p>
        </div>
      </div>
    
      <div class="pub-entry">
        <img src="assets/overview/stfit.png" alt="stfit diagram" />
        <div class="pub-details">
          <a class="pub-title" href="#">ST-FiT: Inductive Spatial-Temporal Forecasting with Limited Training Data</a><br />
          <strong>Zhenyu Lei</strong>, Yushun Dong, Jundong Li, Chen Chen<br />
          <span class="preprint">AAAI 2025 (Oral)</span>
          <p>
            In this paper, we study an under-explored research problem of inductive forecasting with limited training data, which requires models to generalize the learned spatial-temporal dependencies from the nodes with available training temporal data to those nodes without. To handle this problem, we propose ST-FiT that can achieve superior performance without additional fine-tuning. 
          </p>
        </div>
      </div>

      <div class="pub-entry">
        <img src="assets/overview/brainmap.png" alt="brainmap diagram" />
        <div class="pub-details">
          <a class="pub-title" href="#">BrainMAP: Learning Multiple Activation Pathways in Brain Networks</a><br />
          Song Wang*, <strong>Zhenyu Lei*</strong>, Zhen Tan, Jiaqi Ding, Xinyu Zhao, Yushun Dong, Guorong Wu, Tianlong Chen, Chen Chen, Aiying Zhang, Jundong Li<br />
          <span class="preprint">AAAI 2025 (Oral)</span>
          <p>
            While significant progress has been made in understanding
            brain activity through functional connectivity (FC) graphs,
            challenges remain in effectively capturing and interpreting
            the complex, long-range dependencies and multiple pathways that are inherent in these graphs. In this work, we introduce BrainMAP, a novel framework that can extract multiple
            long-range activation pathways with adaptive sequentialization and pathway aggregation.
          </p>
        </div>
      </div>

      <h3>2023</h3>
      <div class="pub-entry">
        <img src="assets/overview/bic.png" alt="brainmap diagram" />
        <div class="pub-details">
          <a class="pub-title" href="#">BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency</a><br />
          <strong>Zhenyu Lei*</strong>, Herun Wan*, Wenqian Zhang, Shangbin Feng, Jundong Li, Qinghua Zheng, Minnan Luo,<br />
          <span class="preprint">ACL 2023</span>
          <p>
            We proposed a bot-detection
            model named BIC. BIC interacts and exchanges information across text modality and graph
            modality by a text-graph interaction module. BIC
            contains a semantic consistency module that derives the inconsistency from tweets by the attention
            weight to identify advanced bots.
          </p>
        </div>
      </div>

    </section>
    

    <section class="industry-experience container" id="experience">
      <h2>‚öôÔ∏è Industrial Experience</h2>
    
    
      <div class="experience-block">
        <div class="experience-header">
          <div class="company-name">AT&T</div>
          <div class="date-range">2025.06 ‚Äì 2025.8</div>
        </div>
        <div class="role-title"><strong>Applied Scientist Intern @ Bedminister</strong></div>
        <div class="experience-meta">
          Host: Dr. <a href="#">Qiong Wu</a> ¬∑ Bedminister, NJ
        </div>
      </div>
    </section>

    <section id="education" class="education-section container">
      <h2>üßë‚Äçüéì Education</h2>
    
      <div class="education-block">
        <div class="education-header">
          <div class="school-name">University of Virginia</div>
          <div class="date-range">2023.08 ‚Äì present</div>
        </div>
        <div class="degree-title"><strong>Ph.D. in Electrical and Computer Engineering</strong></div>
        <div class="education-meta">
          Advisor: Prof. <a href="#">Jundong Li</a>
        </div>
      </div>
    
      <div class="education-block">
        <div class="education-header">
          <div class="school-name">Xi'an Jiaotong University</div>
          <div class="date-range">2019.08 ‚Äì 2023.07</div>
        </div>
        <div class="degree-title"><strong>B.S. in Physics (Honor)</strong></div>
        <div class="education-meta">
          GPA: 89.5 / 100.0<br>
          Advisor: Prof. <a href="#">Minnan Luo</a>
        </div>
      </div>
    </section>


    <section class="service-section container" id="service">
      <h2>üë∑ Service</h2>
      <ul>
        <li><strong>Reviewer:</strong> CIKM (2025), COLM (2024, 2025), KDD (2024, 2025), ARR (Dec 2023‚Äì), NeurIPS (2023)</li>
        <li><strong>Volunteer:</strong> ACL 2023 (virtual)</li>
      </ul>
    </section>
    
    <section class="misc-section container" id="misc">
      <h2>üèä Miscellaneous</h2>
      <ul>
        <li>
          I have the fortune to work with brilliant mentors, collaborators, and advisors during my research journey and I am truly grateful for their guidance and help. If you feel like I can be of some help to your research career, welcome to reach out! ‚òï
        </li>
        <li>I enjoy playing badminton <span aria-hidden="true">üè∏</span> and won the William & Mary Open Group C Men's Doubles Champion <span aria-hidden="true">üèÜ</span>.</li>
        <li>I also love singing <span aria-hidden="true">üé§</span> and playing volleyball <span aria-hidden="true">üèê</span>.</li>
        <li>My favorite singers are Adele and Coldplay, "lights will guide you home, I will try to fix you".</li>
        <li>I love all my friends.</li>
        <li>I completed my undergraduate studies at Xi'an Jiaotong University, where I was very fortunate and grateful to join the <a href="https://luoundergradxjtu.github.io/">LUD Lab</a>.</li>
        <li>I have had the privilege of learning from many inspiring mentors, including <a href="https://bunsenfeng.github.io/">Shangbin Feng</a>, <a href="https://bunsenfeng.github.io/">Yushun Dong</a>, <a href="https://songw-sw.github.io/">Song Wang</a>, <a href="https://zhen-tan-dmml.github.io/">Zhen Tan</a>.</li>
      </ul>
    </section>
    
    <!-- <footer id="footer">
      <div class="container">
        <div class="social">
          <a href="#" target="_blank"
            ><img src="./assets/facebook-icon.svg" alt="Facebook"
          /></a>
          <a href="#" target="_blank"><img src="./assets/twitter-icon.svg" alt="Twitter" /></a>
          <a href="#" target="_blank"
            ><img src="./assets/linkedin-icon.svg" alt="Linkedin"
          /></a>
          <a href="#" target="_blank"><img src="./assets/github-icon.svg" alt="GitHub" /></a>
          <a href="#" target="_blank"
            ><img src="./assets/hashnode-icon.svg" alt="Hashnode"
          /></a>
        </div>
      </div>
    </footer> -->
    
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=MFmJMISOQ2yy5LVFuUUjIqzFiU9Nkzot34IptZKxI08&co=40a2e3&ct=ffffff&cmo=fc6736&cmn=b67352'></script>

    Credits goes to Zhaoxuan Tan and CommunityPro!


    <script src="js/script.js"></script>
  </body>
</html>
